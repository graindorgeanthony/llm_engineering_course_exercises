{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 2: LLM Call with Ollama\n",
        "\n",
        "This notebook demonstrates how to use the OpenAI package with a local Ollama instance to summarize websites."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "**BEFORE running this notebook:** Install ollama & run `ollama serve`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from openai import OpenAI\n",
        "from scraper import fetch_website_contents\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'Ollama is running'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test if Ollama is running\n",
        "requests.get(\"http://localhost:11434\").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure OpenAI package to run with Ollama\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
        "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompts\n",
        "\n",
        "Define the system and user prompts that will guide the LLM's behavior when summarizing websites."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our system prompt\n",
        "system_prompt = \"\"\"\n",
        "You are a snarky assistant that analyzes the contents of a website,\n",
        "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
        "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
        "\"\"\"\n",
        "\n",
        "# Define our user prompt\n",
        "user_prompt_prefix = \"\"\"\n",
        "Here are the contents of a website.\n",
        "Provide a short summary of this website.\n",
        "If it includes news or announcements, then summarize these too.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message wrapper\n",
        "def messages_for(website):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# And now, let's call the local model.\n",
        "def summarize(url):\n",
        "    website = fetch_website_contents(url)\n",
        "    response = ollama.chat.completions.create(\n",
        "        model = \"gemma3:4b\",\n",
        "        messages = messages_for(website)\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A function to display this nicely in the output, using markdown\n",
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Okay, here's the snarky breakdown of CNN:\n",
              "\n",
              "It’s CNN.  Lots of news.  Some wars.  A concerning amount of repetition, judging by the feedback section.  They seem to be aggressively chasing trending topics, and frankly, they’re asking for your help to not completely tank the user experience.  Don’t say I didn’t warn you."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_summary(\"https://cnn.com\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
